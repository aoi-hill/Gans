{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGan_variations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNX+Ir0GcjcLG2etWK+R6QM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3abe019fe9e4f48a22a6d0d3353185c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6811ed610e2c483b9ccf23f755724d03",
              "IPY_MODEL_e9bfec3c6ed447e5976182c3da5e5b8c",
              "IPY_MODEL_e49d4cfb02ac40d58c1c474e03c071b1"
            ],
            "layout": "IPY_MODEL_a1f093b6f4e246a583386393e9c9c953"
          }
        },
        "6811ed610e2c483b9ccf23f755724d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78c0fe67cda5474d927586cb9c021130",
            "placeholder": "​",
            "style": "IPY_MODEL_90866ea4199e45b49235777e33d32d5c",
            "value": "  0%"
          }
        },
        "e9bfec3c6ed447e5976182c3da5e5b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44bd114f6f99452bb7f1cf7c26d5a422",
            "max": 391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86ca9ee0660c4abbaca8d4a78c5ec452",
            "value": 0
          }
        },
        "e49d4cfb02ac40d58c1c474e03c071b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8b292a84781440d841703e6ed2554b7",
            "placeholder": "​",
            "style": "IPY_MODEL_c555ebf4ea9d46e68fd8a757f76ebbb7",
            "value": " 0/391 [00:00&lt;?, ?it/s]"
          }
        },
        "a1f093b6f4e246a583386393e9c9c953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78c0fe67cda5474d927586cb9c021130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90866ea4199e45b49235777e33d32d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44bd114f6f99452bb7f1cf7c26d5a422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ca9ee0660c4abbaca8d4a78c5ec452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8b292a84781440d841703e6ed2554b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c555ebf4ea9d46e68fd8a757f76ebbb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aoi-hill/Gans/blob/main/DCGan_Var1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t7_ZX35CiyXl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "metadata": {
        "id": "z5UtNDxzns3A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c-y8-dOKBkAQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFwFU1yUntYq",
        "outputId": "6c5c6ea1-04ab-46d3-b1cb-d9bbb86120e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels, downsample):\n",
        "        super().__init__()\n",
        "        if downsample:\n",
        "            self.conv1 = nn.Conv2d(input_channels, output_channels,3,2,1)\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels,1,2),\n",
        "                nn.BatchNorm2d(output_channels))\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(input_channels, output_channels,3,1,1)\n",
        "            self.shortcut = nn.Sequential()\n",
        "        \n",
        "        self.direct = nn.Sequential(\n",
        "            self.conv1,\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(output_channels, output_channels, 3,1,1),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU())\n",
        "\n",
        "    def forward(self, inp):\n",
        "        return  nn.ReLU()(self.direct(inp)+self.shortcut(inp))"
      ],
      "metadata": {
        "id": "m-DhOCgRow4T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim=10, im_chan=1, hidden_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.gen1 = self.make_gen_block(input_dim, hidden_dim*8, kernel_size=4, stride=1, padding=0)\n",
        "        self.gen2 = nn.Sequential(\n",
        "            self.make_gen_block(hidden_dim*8, hidden_dim * 4, kernel_size=4, stride=2, padding=1),\n",
        "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=2, padding=1))\n",
        "        self.res1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(hidden_dim*8, hidden_dim*2, kernel_size = 3, stride = 5, padding = 1),\n",
        "            nn.BatchNorm2d(hidden_dim*2),\n",
        "            nn.ReLU(inplace=True))\n",
        "        self.gen3 = self.make_gen_block(hidden_dim * 2, im_chan, kernel_size=4, stride=2, padding=1, final_layer=True)\n",
        "        self.tmp1 = spectral_norm(nn.Conv2d(hidden_dim*2,hidden_dim*2,1))\n",
        "        self.tmp2 = spectral_norm(nn.Conv2d(hidden_dim*2,hidden_dim*2,1))\n",
        "        self.tmp3 = spectral_norm(nn.Conv2d(hidden_dim*2,hidden_dim*2,1))\n",
        "            #self.make_gen_block(hidden_dim, im_chan, kernel_size=4, stride=2, padding=1, final_layer=True),\n",
        "        \n",
        "\n",
        "    def make_gen_block(self, input_dim, output_dim, kernel_size=3, stride=2, padding=0, final_layer=False):\n",
        "        if not final_layer:\n",
        "            return(nn.Sequential(\n",
        "                spectral_norm(nn.ConvTranspose2d(input_dim, output_dim, kernel_size, stride, padding)),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ))\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                spectral_norm(nn.ConvTranspose2d(input_dim, output_dim, kernel_size, stride, padding)),\n",
        "                nn.Tanh())\n",
        "            \n",
        "    def non_local(self, inp): #NOT changing the channels here \n",
        "        print(inp.dtype, '===', inp.get_device())\n",
        "        x1 = self.tmp1(inp)\n",
        "        x2 = self.tmp2(inp)\n",
        "        x1 = x1.view(-1,inp.shape[1])\n",
        "        x2 = x2.view(inp.shape[1],-1)\n",
        "        x3 = torch.matmul(x1,x2) #too much memory\n",
        "        x3 = nn.Softmax(dim=1)(x3)\n",
        "        x =  self.tmp3(inp).view(-1,inp.shape[1])\n",
        "        x3 = torch.matmul(x3,x)\n",
        "        x3 = x3.view(inp.shape) #as channels not changed\n",
        "        return inp+x3\n",
        "\n",
        "    def forward(self, noise):\n",
        "        x = noise.view(len(noise),self.input_dim,1,1)\n",
        "        x = self.gen1(x)\n",
        "        x1 = self.gen2(x)\n",
        "        x2 = self.res1(x)\n",
        "        x = x1+x2\n",
        "        #x = self.non_local(x)\n",
        "        return self.gen3(x)\n",
        "\n",
        "def get_noise(n_samples, input_dim, device='cpu'):\n",
        "    return torch.randn(n_samples,input_dim).to(device)\n"
      ],
      "metadata": {
        "id": "Xnvkwz2UnteX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, im_chan=1, hidden_dim=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.disc = nn.Sequential(\n",
        "            self.make_disc_block(im_chan, hidden_dim, begin=True),\n",
        "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
        "            self.make_disc_block(hidden_dim*2, hidden_dim * 4 - 10),\n",
        "            #self.make_disc_block(hidden_dim*4, 1, final_layer=True)\n",
        "            #self.make_disc_block(hidden_dim*8, 1, final_layer=True),\n",
        "        )\n",
        "        self.fin = self.make_disc_block(self.hidden_dim*4, 1, final_layer=True)\n",
        "\n",
        "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, padding=1, final_layer=False, begin=False):\n",
        "\n",
        "        if not final_layer and not begin:\n",
        "            return nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_channels, output_channels, kernel_size, stride, padding, bias=False)),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "            )\n",
        "        elif not final_layer:\n",
        "             return nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_channels, output_channels, kernel_size, stride,padding, bias=False)),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_channels, output_channels, kernel_size = 4, stride = 1 , padding= 0 , bias=False)),\n",
        "            )\n",
        "\n",
        "    def forward(self, img, one_hot_img):\n",
        "        disc_pred = self.disc(img)\n",
        "        image_one_hot = one_hot[:,:,None,None].repeat(1,1,disc_pred.shape[2],disc_pred.shape[3])\n",
        "        #print(disc_pred.shape,image_one_hot.shape)\n",
        "        x = combine_vectors(disc_pred,image_one_hot) \n",
        "        #print(x.shape)\n",
        "        disc_fin_inp = self.fin(x)\n",
        "       \n",
        "        return disc_pred.view(len(disc_pred), -1)\n"
      ],
      "metadata": {
        "id": "BM5_aBdAntjb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def get_one_hot_labels(labels, n_classes):\n",
        "    return F.one_hot(labels, n_classes)"
      ],
      "metadata": {
        "id": "vgMQV0gkntng"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_vectors(x, y):\n",
        "    return torch.cat((x,y),dim=1)"
      ],
      "metadata": {
        "id": "9aQ2I_TCnttU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=128\n",
        "n_epochs = 200\n",
        "lr = 0.0002\n",
        "z_dim = 64\n",
        "display_step = 500\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "cifar10_shape = (3,32,32)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    CIFAR10('/content/drive/MyDrive/Colab Notebooks/DeepLearningAI/GANs/coursera-gan-specialization-main/Data',train=True, download= True, transform = transform),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "dataloader_test = DataLoader(\n",
        "    CIFAR10('/content/drive/MyDrive/Colab Notebooks/DeepLearningAI/GANs/coursera-gan-specialization-main/Data',train=False, download= True, transform = transform),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_wG2vqdntyP",
        "outputId": "8aa693c2-245d-495f-c28f-a8d0fc68bb3c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_dimensions(z_dim, CIFAR10_shape, n_classes):\n",
        "    generator_input_dim = z_dim + n_classes\n",
        "    discriminator_im_chan = CIFAR10_shape[0] + n_classes\n",
        "    return generator_input_dim, discriminator_im_chan"
      ],
      "metadata": {
        "id": "iesm2rPqnt3s"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_inp1, disc_inp1 = get_input_dimensions(z_dim, cifar10_shape, 10)\n",
        "\n",
        "gen = Generator(gen_inp1,3).to(device)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(),lr,[0.5,0.999])\n",
        "disc = Discriminator(3).to(device)\n",
        "disc_opt = torch.optim.Adam(disc.parameters(),lr,[0.5,0.999])\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m,nn.Conv2d) or isinstance(m,nn.ConvTranspose2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight,0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "        \n",
        "gen = gen.apply(weights_init)\n",
        "disc = disc.apply(weights_init)"
      ],
      "metadata": {
        "id": "RwqkiVgtnt8A"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_weights = []\n",
        "def retrieve_weights(m):\n",
        "    if isinstance(m,nn.Conv2d) or isinstance(m,nn.ConvTranspose2d):\n",
        "        print('1')\n",
        "        "
      ],
      "metadata": {
        "id": "8V_M3HLqJEzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur_step = 0\n",
        "generator_losses = []\n",
        "discriminator_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for data,labels in tqdm(dataloader_train):\n",
        "        cur_batch_size = data.shape[0]\n",
        "\n",
        "        data = data.to(device)\n",
        "        noise = get_noise(cur_batch_size,z_dim,device)\n",
        "        one_hot = get_one_hot_labels(labels.to(device), 10)\n",
        "        gen_inp = combine_vectors(noise,one_hot)\n",
        "        \n",
        "        disc_opt.zero_grad()\n",
        "\n",
        "        gen_out = gen(gen_inp)\n",
        "        disc_inp_fake = gen_out.detach() #combine_vectors(gen_out.detach(), image_one_hot)\n",
        "        #print(disc_inp_fake.shape, one_hot.shape)\n",
        "        disc_inp_real = data #combine_vectors(data, image_one_hot)\n",
        "        disc_fake_pred = disc(disc_inp_fake,one_hot)\n",
        "        disc_real_pred = disc(disc_inp_real,one_hot)\n",
        "        disc_out = torch.cat((disc_fake_pred,disc_real_pred),dim=1)\n",
        "        actual_labels = torch.cat((torch.zeros_like(disc_fake_pred),torch.ones_like(disc_real_pred)),dim=1)\n",
        "        disc_loss = criterion(disc_out,actual_labels)\n",
        "\n",
        "        disc_fake_loss = criterion(disc_out,actual_labels)\n",
        "        disc_loss.backward(retain_graph=True)\n",
        "        disc_opt.step()\n",
        "        \n",
        "        discriminator_losses += [disc_loss.item()]\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "\n",
        "        disc_fake_pred = disc(gen_out,one_hot)\n",
        "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "\n",
        "        generator_losses += [gen_loss.item()]\n",
        "\n",
        "\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
        "            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
        "            print(f\"Step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n",
        "            show_tensor_images(gen_out)\n",
        "            show_tensor_images(data)\n",
        "            step_bins = 20\n",
        "            x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n",
        "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
        "            plt.plot(\n",
        "                range(num_examples // step_bins), \n",
        "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                label=\"Generator Loss\"\n",
        "            )\n",
        "            plt.plot(\n",
        "                range(num_examples // step_bins), \n",
        "                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                label=\"Discriminator Loss\"\n",
        "            )\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        elif cur_step == 0:\n",
        "            print(\"Working Now !\")\n",
        "        cur_step += 1\n",
        "\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534,
          "referenced_widgets": [
            "c3abe019fe9e4f48a22a6d0d3353185c",
            "6811ed610e2c483b9ccf23f755724d03",
            "e9bfec3c6ed447e5976182c3da5e5b8c",
            "e49d4cfb02ac40d58c1c474e03c071b1",
            "a1f093b6f4e246a583386393e9c9c953",
            "78c0fe67cda5474d927586cb9c021130",
            "90866ea4199e45b49235777e33d32d5c",
            "44bd114f6f99452bb7f1cf7c26d5a422",
            "86ca9ee0660c4abbaca8d4a78c5ec452",
            "f8b292a84781440d841703e6ed2554b7",
            "c555ebf4ea9d46e68fd8a757f76ebbb7"
          ]
        },
        "id": "MIBcg0QMnuAF",
        "outputId": "b31973dc-8697-4c21-d3dd-1f40c3e9c978"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3abe019fe9e4f48a22a6d0d3353185c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32 === 0\n",
            "a\n",
            "torch.Size([128, 128, 16, 16]) torch.Size([128, 128, 16, 16])\n",
            "b torch.Size([32768, 128]) torch.Size([128, 32768])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-619870a24346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdisc_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mgen_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdisc_inp_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#combine_vectors(gen_out.detach(), image_one_hot)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print(disc_inp_fake.shape, one_hot.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-dfa3af1aef60>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, noise)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-dfa3af1aef60>\u001b[0m in \u001b[0;36mnon_local\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 14.76 GiB total capacity; 8.74 GiB already allocated; 1.43 GiB free; 12.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_4od5DutG9gh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}